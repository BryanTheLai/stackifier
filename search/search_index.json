{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Stackifier","text":"<p>Lightweight data collection library for WhatsApp AI agents - log conversations, tool calls, and metrics to JSONL or S3 with OpenAI-compatible schema.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>pip install stackifier\n</code></pre> <pre><code>from stackifier import TraceHook, FileWriter\n\ntrace = TraceHook(storage=FileWriter(path=\"logs/conversations.jsonl\"))\n\ntrace.log_message(role=\"user\", content=\"Hello! What's the weather?\")\ntrace.log_message(role=\"assistant\", content=\"Let me check that for you.\")\ntrace.flush()\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>For full documentation, examples, and API reference, see the README.md in the project root.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>OpenAI Chat Schema: Store every turn using standard <code>{system,user,assistant,tool}</code> roles</li> <li>Local First: Append to JSONL files by default, zero-ops setup</li> <li>S3 Optional: Drop-in cloud storage with boto3</li> <li>WhatsApp Adapters: Normalize Meta Cloud API and Twilio webhooks</li> <li>LLM Integrations: Native support for LiteLLM, LangChain, LangGraph, OpenRouter</li> <li>Rich Metrics: Capture timing, tokens, costs, tool latencies</li> </ul>"},{"location":"#links","title":"Links","text":"<ul> <li>GitHub Repository</li> <li>PyPI Package</li> <li>Installation &amp; Usage</li> </ul>"}]}